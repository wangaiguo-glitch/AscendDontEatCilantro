

import gradio as gr
import cv2
import numpy as np
import time
import threading
import json
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# ==================== å¯¼å…¥ç°æœ‰æ¨¡å— ====================
print("ğŸ”„ æ­£åœ¨å¯¼å…¥ç°æœ‰æ¨¡å—...")

# ç”¨äºæ¨¡æ‹Ÿçš„åå¤‡å‡½æ•°ï¼ˆå½“å¯¼å…¥å¤±è´¥æ—¶ä½¿ç”¨ï¼‰
def create_fallback_functions():
    """åˆ›å»ºåå¤‡å‡½æ•°ï¼Œå½“å¯¼å…¥å¤±è´¥æ—¶ä½¿ç”¨"""
    
    def run_vlm_analysis(frame):
        """æ¨¡æ‹ŸVLMåˆ†æ"""
        return f"æ¨¡æ‹ŸVLMåˆ†æ - æ£€æµ‹æ—¶é—´: {time.strftime('%H:%M:%S')}"
    
    def run_yolo_detection(frame, conf_thres=0.5, iou_thres=0.45):
        """æ¨¡æ‹ŸYOLOæ£€æµ‹"""
        return {
            "category_id": [0, 2],
            "bbox": [[100, 100, 50, 100], [300, 150, 50, 50]],
            "score": [0.85, 0.75]
        }
    
    def run_heatmap_generation(frame):
        """æ¨¡æ‹Ÿçƒ­åŠ›å›¾ç”Ÿæˆ"""
        # ç”Ÿæˆéšæœºæ·±åº¦å›¾
        depth_map = np.random.rand(frame.shape[0], frame.shape[1]) * 255
        return depth_map.astype(np.float32)
    
    def draw_depth_visualization(depth_map):
        """æ¨¡æ‹Ÿçƒ­åŠ›å›¾å¯è§†åŒ–"""
        # ç®€å•çš„é¢œè‰²æ˜ å°„
        depth_uint8 = depth_map.astype(np.uint8)
        heatmap = cv2.applyColorMap(depth_uint8, cv2.COLORMAP_JET)
        return heatmap
    
    return {
        'vlm_analysis': run_vlm_analysis,
        'yolo_detection': run_yolo_detection,
        'heatmap_generation': run_heatmap_generation,
        'draw_depth': draw_depth_visualization
    }

# å°è¯•å¯¼å…¥çœŸå®æ¨¡å—
try:
    # å¯¼å…¥YOLOæ¨¡å—
    from run_yolo import detect_once, draw_in_memory
    
    # å¯¼å…¥çƒ­åŠ›å›¾æ¨¡å—
    from run_midas import depth_once, draw_depth
    
    # å¯¼å…¥VLMæ¨¡å—
    from vlm import vlm_infer
    
    print("âœ… æˆåŠŸå¯¼å…¥æ‰€æœ‰ç°æœ‰æ¨¡å—")
    
    # åŒ…è£…å‡½æ•°ï¼Œä»¥ä¾¿ç»Ÿä¸€è°ƒç”¨
    def run_vlm_analysis(frame):
        """è°ƒç”¨vlm_inferå‡½æ•°"""
        try:
            result = vlm_infer(frame)
            if result:
                # è¿™é‡Œéœ€è¦æ ¹æ®vlm_inferçš„å®é™…è¿”å›å€¼è°ƒæ•´
                # å‡è®¾è¿”å›çš„æ˜¯åŒ…å«ç­”æ¡ˆçš„å­—å…¸
                return f"VLMåˆ†æç»“æœ: {result}"
            return "VLMåˆ†æå®Œæˆï¼Œæ— å…·ä½“ç»“æœ"
        except Exception as e:
            return f"VLMåˆ†æå‡ºé”™: {str(e)}"
    
    # æ³¨æ„ï¼šYOLOå’ŒMiDaSéœ€è¦æ¨¡å‹å‚æ•°ï¼Œæˆ‘ä»¬æš‚æ—¶ç”¨Noneå ä½
    # å®é™…ä½¿ç”¨æ—¶éœ€è¦åœ¨åˆå§‹åŒ–æ—¶åŠ è½½æ¨¡å‹
    def run_yolo_detection(frame, conf_thres=0.5, iou_thres=0.45):
        """è°ƒç”¨detect_onceå‡½æ•°"""
        try:
            # è¿™é‡Œéœ€è¦ä¼ å…¥æ¨¡å‹ï¼Œæš‚æ—¶è¿”å›æ¨¡æ‹Ÿç»“æœ
            # å®é™…ä½¿ç”¨æ—¶ï¼šreturn detect_once(yolo_model, frame, conf_thres, iou_thres)
            return {
                "category_id": [0, 2],
                "bbox": [[100, 100, 50, 100], [300, 150, 50, 50]],
                "score": [0.85, 0.75]
            }
        except Exception as e:
            print(f"YOLOæ£€æµ‹å‡ºé”™: {e}")
            return {"category_id": [], "bbox": [], "score": []}
    
    def draw_yolo_visualization(frame, detection_result):
        """è°ƒç”¨draw_in_memoryå‡½æ•°"""
        try:
            # éœ€è¦data_nameså‚æ•°ï¼Œè¿™é‡Œä½¿ç”¨COCOç±»åˆ«åå‰å‡ ä¸ªä½œä¸ºç¤ºä¾‹
            data_names = ["person", "bicycle", "car", "motorcycle", "airplane"]
            return draw_in_memory(frame, detection_result, data_names)
        except Exception as e:
            print(f"ç»˜åˆ¶YOLOç»“æœå‡ºé”™: {e}")
            return frame
    
    def run_heatmap_generation(frame):
        """è°ƒç”¨depth_onceå‡½æ•°"""
        try:
            # è¿™é‡Œéœ€è¦ä¼ å…¥æ¨¡å‹ï¼Œæš‚æ—¶è¿”å›æ¨¡æ‹Ÿç»“æœ
            # å®é™…ä½¿ç”¨æ—¶ï¼šreturn depth_once(midas_model, frame)
            return np.random.rand(frame.shape[0], frame.shape[1]) * 255
        except Exception as e:
            print(f"çƒ­åŠ›å›¾ç”Ÿæˆå‡ºé”™: {e}")
            return np.zeros((frame.shape[0], frame.shape[1]))
    
    def draw_depth_visualization(depth_map):
        """è°ƒç”¨draw_depthå‡½æ•°"""
        try:
            return draw_depth(depth_map)
        except Exception as e:
            print(f"ç»˜åˆ¶çƒ­åŠ›å›¾å‡ºé”™: {e}")
            # ç®€å•çš„å¤‡é€‰æ–¹æ¡ˆ
            depth_uint8 = depth_map.astype(np.uint8)
            return cv2.applyColorMap(depth_uint8, cv2.COLORMAP_JET)
    
    # åˆ›å»ºå‡½æ•°å­—å…¸
    functions = {
        'vlm_analysis': run_vlm_analysis,
        'yolo_detection': run_yolo_detection,
        'draw_yolo': draw_yolo_visualization,
        'heatmap_generation': run_heatmap_generation,
        'draw_depth': draw_depth_visualization
    }
    
except ImportError as e:
    print(f"âš ï¸ å¯¼å…¥ç°æœ‰æ¨¡å—å¤±è´¥: {e}")
    print("å°†ä½¿ç”¨æ¨¡æ‹Ÿå‡½æ•°ä½œä¸ºåå¤‡æ–¹æ¡ˆ")
    functions = create_fallback_functions()

# ==================== å…¨å±€çŠ¶æ€ç®¡ç† ====================
class AppState:
    """åº”ç”¨çŠ¶æ€ç®¡ç†"""
    def __init__(self):
        self.is_processing = False
        self.vlm_output = "ç­‰å¾…VLMåˆ†æ..."
        self.voice_text = "ç­‰å¾…è¯­éŸ³æ’­æŠ¥..."
        self.last_vlm_time = 0
        self.vlm_interval = 10  # VLMåˆ†æé—´éš”ï¼ˆç§’ï¼‰
        self.current_params = {
            'confidence': 0.5,
            'iou': 0.45,
            'heatmap_alpha': 0.6
        }

state = AppState()

# ==================== æ ¸å¿ƒå¤„ç†å‡½æ•° ====================
def process_video_generator(video_source):
    """
    å¤„ç†è§†é¢‘æµçš„ç”Ÿæˆå™¨å‡½æ•°
    è¿”å›: (yolo_image, heatmap_image, vlm_output, voice_text)
    """
    # æ‰“å¼€è§†é¢‘æº
    if video_source == "æ‘„åƒå¤´" or video_source == "0":
        cap = cv2.VideoCapture(0)
    else:
        cap = cv2.VideoCapture(video_source)
    
    if not cap.isOpened():
        print("âŒ æ— æ³•æ‰“å¼€è§†é¢‘æº")
        return
    
    print(f"ğŸ¥ å¼€å§‹å¤„ç†è§†é¢‘æº: {video_source}")
    
    try:
        while state.is_processing:
            ret, frame = cap.read()
            if not ret:
                break
            
            current_time = time.time()
            
            # 1. YOLOç›®æ ‡æ£€æµ‹
            yolo_result = functions['yolo_detection'](
                frame, 
                conf_thres=state.current_params['confidence'],
                iou_thres=state.current_params['iou']
            )
            yolo_image = functions['draw_yolo'](frame, yolo_result)
            
            # 2. çƒ­åŠ›å›¾ç”Ÿæˆ
            depth_map = functions['heatmap_generation'](frame)
            heatmap_image = functions['draw_depth'](depth_map)
            
            # 3. VLMåˆ†æï¼ˆæ¯10ç§’ä¸€æ¬¡ï¼‰
            vlm_text = state.vlm_output
            voice_text = state.voice_text
            
            if current_time - state.last_vlm_time >= state.vlm_interval:
                # æ›´æ–°çŠ¶æ€ä¸º"æ­£åœ¨åˆ†æä¸­"
                state.vlm_output = "VLMæ­£åœ¨åˆ†æä¸­..."
                vlm_text = state.vlm_output
                
                # åœ¨è¿™é‡Œå®é™…è°ƒç”¨VLMåˆ†æ
                # ä½¿ç”¨çº¿ç¨‹é¿å…é˜»å¡
                def call_vlm_analysis():
                    try:
                        result = functions['vlm_analysis'](frame)
                        state.vlm_output = f"VLMåˆ†æç»“æœï¼š{result}"
                        
                        # ç”Ÿæˆè¯­éŸ³æ’­æŠ¥æ–‡æœ¬
                        if yolo_result and len(yolo_result.get('category_id', [])) > 0:
                            count = len(yolo_result['category_id'])
                            state.voice_text = f"æ£€æµ‹åˆ°{count}ä¸ªéšœç¢ç‰©ï¼Œè¯·æ³¨æ„é¿è®©"
                        else:
                            state.voice_text = "å½“å‰ç”»é¢å®‰å…¨ï¼Œæœªæ£€æµ‹åˆ°éšœç¢ç‰©"
                        
                        print(f"âœ… VLMåˆ†æå®Œæˆ: {result[:50]}...")
                    except Exception as e:
                        print(f"âŒ VLMåˆ†æå‡ºé”™: {e}")
                        state.vlm_output = f"VLMåˆ†æå‡ºé”™: {str(e)[:100]}"
                
                # åœ¨æ–°çº¿ç¨‹ä¸­æ‰§è¡ŒVLMåˆ†æ
                vlm_thread = threading.Thread(target=call_vlm_analysis)
                vlm_thread.daemon = True
                vlm_thread.start()
                
                state.last_vlm_time = current_time
            
            # è½¬æ¢å›¾åƒæ ¼å¼
            yolo_rgb = cv2.cvtColor(yolo_image, cv2.COLOR_BGR2RGB)
            heatmap_rgb = cv2.cvtColor(heatmap_image, cv2.COLOR_BGR2RGB)
            
            yield yolo_rgb, heatmap_rgb, state.vlm_output, state.voice_text
            
            # æ§åˆ¶å¸§ç‡
            time.sleep(0.03)
    
    finally:
        cap.release()
        print("âœ… è§†é¢‘å¤„ç†ç»“æŸ")

# ==================== Gradioå›è°ƒå‡½æ•° ====================
def start_processing(video_source):
    """å¼€å§‹å¤„ç†è§†é¢‘"""
    state.is_processing = True
    return "å¼€å§‹å¤„ç†...", gr.update(visible=False)

def stop_processing():
    """åœæ­¢å¤„ç†"""
    state.is_processing = False
    return "å·²åœæ­¢", gr.update(visible=True)

def update_parameters(confidence, iou, heatmap_alpha):
    """æ›´æ–°å¤„ç†å‚æ•°"""
    state.current_params = {
        'confidence': confidence,
        'iou': iou,
        'heatmap_alpha': heatmap_alpha
    }
    print(f"âš™ï¸ å‚æ•°å·²æ›´æ–°: {state.current_params}")

# ==================== åˆ›å»ºGradioç•Œé¢ ====================
def create_interface():
    """åˆ›å»ºGradioç•Œé¢"""
    
    # è‡ªå®šä¹‰CSS
    css = """
    .gradio-container {
        max-width: 1400px;
        margin: 0 auto;
    }
    
    .voice-alert-box {
        animation: fadeIn 0.5s, fadeOut 1s 4s forwards;
        background: linear-gradient(135deg, #4CAF50, #45a049);
        color: white;
        padding: 15px;
        border-radius: 10px;
        margin: 10px 0;
        font-weight: bold;
        box-shadow: 0 4px 12px rgba(0,0,0,0.2);
    }
    
    @keyframes fadeIn {
        from { opacity: 0; transform: translateY(-10px); }
        to { opacity: 1; transform: translateY(0); }
    }
    
    @keyframes fadeOut {
        from { opacity: 1; transform: translateY(0); }
        to { opacity: 0; transform: translateY(-10px); }
    }
    """
    
    with gr.Blocks(css=css, title="å®æ—¶éšœç¢ç‰©æ£€æµ‹ç³»ç»Ÿ", theme=gr.themes.Soft()) as app:
        gr.Markdown("""
        # ğŸš— å®æ—¶éšœç¢ç‰©æ£€æµ‹ä¸æ’­æŠ¥ç³»ç»Ÿ
        
        **åŠŸèƒ½è¯´æ˜ï¼š**
        1. ğŸ¯ **YOLOç›®æ ‡æ£€æµ‹**ï¼šå®æ—¶æ£€æµ‹éšœç¢ç‰©
        2. ğŸ”¥ **æ·±åº¦çƒ­åŠ›å›¾**ï¼šæ˜¾ç¤ºåœºæ™¯æ·±åº¦ä¿¡æ¯
        3. ğŸ§  **VLMåœºæ™¯åˆ†æ**ï¼šæ¯10ç§’åˆ†æä¸€æ¬¡ç¯å¢ƒ
        4. ğŸ”Š **è¯­éŸ³æ’­æŠ¥æç¤º**ï¼šæ–‡æœ¬å½¢å¼çš„å®‰å…¨æé†’
        
        ---
        """)
        
        with gr.Row():
            with gr.Column(scale=1):
                # æ§åˆ¶é¢æ¿
                gr.Markdown("### ğŸ® æ§åˆ¶é¢æ¿")
                
                video_source = gr.Radio(
                    choices=["æ‘„åƒå¤´", "è§†é¢‘æ–‡ä»¶"],
                    value="æ‘„åƒå¤´",
                    label="é€‰æ‹©è§†é¢‘æº"
                )
                
                video_file = gr.File(
                    label="ä¸Šä¼ è§†é¢‘æ–‡ä»¶",
                    file_types=[".mp4", ".avi", ".mov"],
                    visible=False
                )
                
                with gr.Row():
                    start_btn = gr.Button("â–¶ï¸ å¼€å§‹", variant="primary", size="lg")
                    stop_btn = gr.Button("â¹ï¸ åœæ­¢", variant="secondary", size="lg")
                
                # å‚æ•°è°ƒèŠ‚
                gr.Markdown("### âš™ï¸ å®æ—¶å‚æ•°è°ƒèŠ‚")
                
                confidence_slider = gr.Slider(
                    minimum=0.1,
                    maximum=0.9,
                    value=0.5,
                    step=0.05,
                    label="ç½®ä¿¡åº¦é˜ˆå€¼",
                    interactive=True
                )
                
                iou_slider = gr.Slider(
                    minimum=0.1,
                    maximum=0.9,
                    value=0.45,
                    step=0.05,
                    label="IOUé˜ˆå€¼",
                    interactive=True
                )
                
                heatmap_alpha = gr.Slider(
                    minimum=0.1,
                    maximum=1.0,
                    value=0.6,
                    step=0.1,
                    label="çƒ­åŠ›å›¾é€æ˜åº¦",
                    interactive=True
                )
                
                # çŠ¶æ€æ˜¾ç¤º
                status_display = gr.Textbox(
                    label="ç³»ç»ŸçŠ¶æ€",
                    value="å°±ç»ª",
                    interactive=False
                )
            
            with gr.Column(scale=2):
                # ç»“æœæ˜¾ç¤ºåŒºåŸŸ
                gr.Markdown("### ğŸ“Š å®æ—¶æ£€æµ‹ç»“æœ")
                
                with gr.Row():
                    yolo_output = gr.Image(
                        label="YOLOæ£€æµ‹ç»“æœ",
                        height=350,
                        show_label=True
                    )
                    
                    heatmap_output = gr.Image(
                        label="æ·±åº¦çƒ­åŠ›å›¾",
                        height=350,
                        show_label=True
                    )
                
                # VLMåˆ†æç»“æœ
                gr.Markdown("### ğŸ§  VLMåœºæ™¯åˆ†æ")
                vlm_output = gr.Textbox(
                    label="åˆ†æç»“æœ",
                    lines=4,
                    value="ç­‰å¾…VLMåˆ†æ...",
                    interactive=False,
                    show_label=True
                )
                
                # è¯­éŸ³æ’­æŠ¥å†…å®¹
                gr.Markdown("### ğŸ”Š è¯­éŸ³æ’­æŠ¥")
                voice_output = gr.Textbox(
                    label="æ’­æŠ¥å†…å®¹",
                    lines=2,
                    value="ç­‰å¾…è¯­éŸ³æ’­æŠ¥...",
                    interactive=False,
                    show_label=True
                )
        
        # ===== äº‹ä»¶ç»‘å®š =====
        
        # è§†é¢‘æºåˆ‡æ¢
        def toggle_video_source(choice):
            return gr.update(visible=(choice == "è§†é¢‘æ–‡ä»¶"))
        
        video_source.change(
            fn=toggle_video_source,
            inputs=video_source,
            outputs=video_file
        )
        
        # å‚æ•°æ›´æ–°
        confidence_slider.change(
            fn=update_parameters,
            inputs=[confidence_slider, iou_slider, heatmap_alpha],
            outputs=[]
        )
        
        iou_slider.change(
            fn=update_parameters,
            inputs=[confidence_slider, iou_slider, heatmap_alpha],
            outputs=[]
        )
        
        heatmap_alpha.change(
            fn=update_parameters,
            inputs=[confidence_slider, iou_slider, heatmap_alpha],
            outputs=[]
        )
        
        # å¼€å§‹å¤„ç†
        start_btn.click(
            fn=start_processing,
            inputs=video_source,
            outputs=[status_display, start_btn]
        ).then(
            fn=process_video_generator,
            inputs=video_source,
            outputs=[yolo_output, heatmap_output, vlm_output, voice_output]
        )
        
        # åœæ­¢å¤„ç†
        stop_btn.click(
            fn=stop_processing,
            inputs=[],
            outputs=[status_display, start_btn]
        )
        
        # è¯­éŸ³æ’­æŠ¥æ¸å˜æ•ˆæœ
        app.load(
            fn=None,
            inputs=[],
            outputs=[],
            js="""
            function showVoiceAlert(text) {
                if (!text || text === 'ç­‰å¾…è¯­éŸ³æ’­æŠ¥...') return;
                
                // åˆ›å»ºæç¤ºæ¡†
                const alertDiv = document.createElement('div');
                alertDiv.className = 'voice-alert-box';
                alertDiv.innerHTML = 'ğŸ”Š ' + text;
                
                // æ·»åŠ åˆ°é¡µé¢é¡¶éƒ¨
                const container = document.querySelector('.gradio-container');
                if (container) {
                    // ç§»é™¤æ—§çš„æç¤º
                    const oldAlerts = container.querySelectorAll('.voice-alert-box');
                    oldAlerts.forEach(alert => alert.remove());
                    
                    // æ’å…¥æ–°æç¤º
                    container.insertBefore(alertDiv, container.firstChild);
                    
                    // 5ç§’åç§»é™¤
                    setTimeout(() => {
                        if (alertDiv.parentNode) {
                            alertDiv.remove();
                        }
                    }, 5000);
                }
            }
            
            // ç›‘å¬è¯­éŸ³æ’­æŠ¥æ›´æ–°
            setInterval(() => {
                const voiceBox = document.querySelector('textarea[label="æ’­æŠ¥å†…å®¹"]');
                if (voiceBox && voiceBox.value) {
                    showVoiceAlert(voiceBox.value);
                }
            }, 1000);
            """
        )
        
        # é¡µè„š
        gr.Markdown("""
        ---
        **ç³»ç»Ÿä¿¡æ¯ï¼š**
        - ğŸ“… ç‰ˆæœ¬: 1.0.0
        - ğŸ—ï¸ æ¡†æ¶: Gradio + MindSpore Lite
        - ğŸ“ åŸºäºç°æœ‰é¡¹ç›®ç»“æ„
        
        *æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªæ¼”ç¤ºç‰ˆæœ¬ï¼Œå®é™…åŠŸèƒ½å–å†³äºæ¨¡å‹åŠ è½½æƒ…å†µ*
        """)
    
    return app

# ==================== ä¸»å‡½æ•° ====================
def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸš€ å®æ—¶éšœç¢ç‰©æ£€æµ‹ç³»ç»Ÿ - Gradioç‰ˆæœ¬")
    print("=" * 60)
    print("åŸºäºç°æœ‰é¡¹ç›®ç»“æ„ï¼Œè°ƒç”¨ç°æœ‰æ¨¡å—")
    print("VLMåˆ†æé—´éš”: 10ç§’")
    print("=" * 60)
    
    try:
        # åˆ›å»ºç•Œé¢
        app = create_interface()
        
        # å¯åŠ¨åº”ç”¨
        app.launch(
            server_name="0.0.0.0",
            server_port=7860,
            share=False,
            debug=True,
            show_error=True
        )
        
    except Exception as e:
        print(f"âŒ åº”ç”¨å¯åŠ¨å¤±è´¥: {e}")
        print("è¯·æ£€æŸ¥ï¼š")
        print("1. ç«¯å£7860æ˜¯å¦è¢«å ç”¨")
        print("2. ä¾èµ–åŒ…æ˜¯å¦å®‰è£…: pip install gradio opencv-python")
        print("3. ç°æœ‰æ¨¡å—è·¯å¾„æ˜¯å¦æ­£ç¡®")

if __name__ == "__main__":
    main()